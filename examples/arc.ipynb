{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Abstraction and Reasoning Corpus (ARC)\n",
    "\n",
    "#### ARCathon\n",
    "\n",
    "From the [ARCathon website](https://lab42.global/arcathon/):\n",
    "\n",
    "> \"ARCathon is a worldwide AI competition hosted in Davos, Switzerland. The challenge invites individual participants and representatives from companies and institutions to solve ARC, a task deemed impossible for state-of-the-art AI models. The intelligence test for algorithms was created by [FranÃ§ois Chollet](https://fchollet.com/), a Google Senior Staff Engineer and Co-Host of ARCathon.\n",
    "\n",
    "> \"ARC consists of 1,000 tasks, including 100 secret ones that make up the private test set. The competition aims to develop AI capable of solving these private tasks without prior knowledge, requiring advanced abstraction abilities. While humans typically solve 80% of ARC tasks, current algorithms only reach 30.5% - a world record achieved by aggregating existing algorithms designed to solve ARC. Learn more about ARC on our [ARC Page](https://lab42.global/arc/) and Chollet's 2019 paper [On the Measure of Intelligence](https://arxiv.org/abs/1911.01547v2).\"\n",
    "\n",
    "> \"Arcathon allows the use of the code and data for Open Source Code under [Apache 2.0 license](https://opensource.org/licenses/Apache-2.0), and any purpose, licensed under [Apache 2.0](https://opensource.org/licenses/Apache-2.0).\"\n",
    "\n",
    "#### ARC Task\n",
    "- An ARC task consists of several example tests of how to solve the task and usually one test that you must solve.\n",
    "- Each test consists of one input - what it looks like before - and one output - what it should look like after.\n",
    "- Each test input consists of a grid with a certain height and width, where each of the cells can have one of ten colors.\n",
    "- Your task is to find out how to transform the input to achieve the output, based on the examples!\n",
    "\n",
    "#### ARC Data\n",
    "Each task is a .json file within the zip file which contains \n",
    "  - 400 training tasks \n",
    "  - 400 evaluation tasks\n",
    "\n",
    "#### Evals Approach\n",
    "\n",
    "The goal of this notebook is to evaluate model's abstract reasoning abilities via the ARC task data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install Evals if you haven't already\n",
    "# %pip install -e ../."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!curl -O https://lab42.global/wp-content/uploads/2022/08/ARC-800-tasks.zip\n",
    "!tar -xf ARC-800-tasks.zip "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import glob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_to_chatml(data, cutoff_max_tokens_sample):\n",
    "    \"\"\"\n",
    "    This function takes a string and converts it to a ChatML object.\n",
    "    \"\"\"\n",
    "    chatml_data = [] # strip spaces and newlines from the input and output with \n",
    "    reference = str(data[\"train\"]).replace(\" \", \"\").replace(\"\\n\", \"\")\n",
    "    inputmatrix = str(data[\"test\"][0][\"input\"]).replace(\" \", \"\").replace(\"\\n\", \"\")\n",
    "    outputmatrix = str(data[\"test\"][0][\"output\"]).replace(\" \", \"\").replace(\"\\n\", \"\")\n",
    "    user_query = f\"Your task: generate a new output grid for the following unseen input grid, applying the same pattern shared among the training pairs. Input: { inputmatrix } Generate only the 2D output grid in a cleansed format of \\\"[[],[],...,[]]\\\" (no spaces like \\\" \\\" and no \\\"\\\\n\\\"). Output:\"\n",
    "\n",
    "    chatml_example = {\n",
    "        \"input\": [\n",
    "            {\"role\": \"system\", \"content\": f\"You're AbstractReasonGPT, an expert at analyzing pairs of 2D grids that are filled with integers, each representing a different color. You're the best in the world at finding the patterns and generating outputs for new inputs that apply the same pattern. An abstract, conceptual pattern exists between all of the following pairs. {reference}\"},\n",
    "            {\"role\": \"user\", \"content\": user_query}\n",
    "        ],\n",
    "        \"ideal\": str(outputmatrix)\n",
    "    }\n",
    "    # if the chatml_example is too long, we do not use it\n",
    "    if len(str(chatml_example)) > cutoff_max_tokens_sample:\n",
    "        return chatml_data    \n",
    "    chatml_data.append(chatml_example)    \n",
    "    return chatml_data\n",
    "\n",
    "def save_chatml_to_file(chatml_data, filename):\n",
    "    \"\"\"\n",
    "    Saves the given chatml data to the given file.\n",
    "    \"\"\"\n",
    "    with open(filename, 'w') as f:\n",
    "        for example in chatml_data:\n",
    "            f.write(json.dumps(example) + '\\n')\n",
    "\n",
    "def read_json_files(directory, cutoff_max_tokens_sample):\n",
    "    \"\"\" \n",
    "    Reads all JSON files in the given directory and returns them as a list. \n",
    "    \"\"\"\n",
    "    chatml_data = []\n",
    "    for file in glob.glob(os.path.join(directory, '*.json')):\n",
    "        with open(file, 'r') as f:\n",
    "            data = json.load(f)\n",
    "            chatml_data.extend(convert_to_chatml(data, cutoff_max_tokens_sample))\n",
    "    return chatml_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cut off the sample if it is too long to avoid errors, so this limits training set\n",
    "# GPT-4 allows you to increase this well beyond included prompts and completions\n",
    "cutoff_max_tokens_sample = 2048\n",
    "\n",
    "# Run the data processing pipelines\n",
    "# Training data set\n",
    "training_output_file = \"../evals/registry/data/abstract_reasoning_arc/training.jsonl\"\n",
    "training_directory = './training/'\n",
    "training_chatml_data = read_json_files(training_directory, cutoff_max_tokens_sample)\n",
    "save_chatml_to_file(training_chatml_data, training_output_file)\n",
    "\n",
    "# Evaluation data set\n",
    "evaluation_output_file = \"../evals/registry/data/abstract_reasoning_arc/evaluation.jsonl\"\n",
    "evaluation_directory = './evaluation/'\n",
    "evaluation_chatml_data = read_json_files(evaluation_directory, cutoff_max_tokens_sample)\n",
    "save_chatml_to_file(evaluation_chatml_data, evaluation_output_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run the evaluation with gpt-3.5-turbo on the generated data\n",
    "# make sure you've set os.environ[\"OPENAI_API_KEY\"] to your API key\n",
    "!oaieval gpt-3.5-turbo abstract-reasoning-arc --max_samples 10"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
