{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40962c90",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict Global Mean Sea Level (GMSL) variation with Global Isometric Adjustment (GIA).\n",
    "# GMSL refers to the average height of the sea surface across the entire globe. \n",
    "# GIA is the response of the Earth's crust to the redistribution of mass due to changes in ice mass on land. \n",
    "# This change in ice mass impacts global sea level; GMSA with GIA refers to Global Mean Sea Level variation \n",
    "# with the results of those changes subtracted to reflect the actual sea level change by other factors. \n",
    "# This eval attempts to determine the accuracy of predicting GMSL with and without GIA.\n",
    "# The version below provides brief context about what the numbers mean. GPT-3.5 and 4 are both fully knowledgeable\n",
    "# of the terms used. The number returned by the model should be the GMSL with the GIA subtracted, in essence \n",
    "# predicting the GIA blind."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e986b08c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The GMSL data was generated using the Integrated Multi-Mission Ocean Altimeter Data for \n",
    "# Climate Research (http://podaac.jpl.nasa.gov/dataset/MERGED_TP_J1_OSTM_OST_ALL_V51). It combines\n",
    "# Sea Surface Heights from the TOPEX/Poseidon, Jason-1, OSTM/Jason-2, Jason-3, and Sentinel-6 Michael Freilich\n",
    "# missions to a common terrestrial reference frame with all inter-mission biases, range and geophysical corrections\n",
    "# applied and placed onto a georeferenced orbit.  This creates a consistent data record throughout \n",
    "# time, regardless of the instrument used.  Note, the most recent estimates of GMSL (post March 28, 2022)\n",
    "# derived from the Sentinel-6 Michael Freilich mission are preliminary as validation and \n",
    "# reprocessing procedures for Sentinel-6 are ongoing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4d0e700",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data source and source of above information block:\n",
    "# GSFC. 2021. Global Mean Sea Level Trend from Integrated Multi-Mission Ocean Altimeters TOPEX/Poseidon\n",
    "# Jason-1, OSTM/Jason-2, and Jason-3 Version 5.1. Ver. 5.1 PO.DAAC, CA, USA.\n",
    "# Dataset accessed [2023-04-20] at https://doi.org/10.5067/GMSLM-TJ151."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d5d523a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download data set at NASA Earthdata Search. Collection name: \n",
    "# Global Mean Sea Level Trend from Integrated Multi-Mission Ocean Altimeters TOPEX/Poseidon, Jason-1, OSTM/Jason-2, and Jason-3 Version 5.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d3feb4e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import openai\n",
    "import os\n",
    "import random\n",
    "import evals\n",
    "import evals.metrics\n",
    "import re\n",
    "from sklearn.metrics import r2_score\n",
    "from math import sqrt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "69abc074",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is the main class that is referenced in gmsl_predictor.yaml and is used by oaievals.py.\n",
    "class GMSLPredictor(evals.Eval):\n",
    "    def __init__(self, train_jsonl, test_jsonl, train_samples_per_prompt=10, completion_fns=None, **kwargs):\n",
    "        super().__init__(completion_fns=completion_fns, **kwargs)\n",
    "        self.train_jsonl = train_jsonl\n",
    "        self.test_jsonl = test_jsonl\n",
    "        self.train_samples_per_prompt = train_samples_per_prompt\n",
    "        self.api_key = os.environ[\"OPENAI_API_KEY\"]\n",
    "        openai.api_key = self.api_key\n",
    "# This function is called by the run function of oaieval.py.\n",
    "    def run(self, recorder):\n",
    "        # Define the objects I used to later get R^2 data.\n",
    "        actual_gmsl_list = []\n",
    "        predicted_gmsl_list = []\n",
    "        # Define the samples and send the test samples to eval_all_samples in eval.py.\n",
    "        self.train_samples = evals.get_jsonl(self.train_jsonl)\n",
    "        test_samples = evals.get_jsonl(self.test_jsonl)\n",
    "        results = self.eval_all_samples(recorder, test_samples)\n",
    "        \n",
    "        # Append the results to my lists of ideal and predicted values for R^2 calculation.\n",
    "        for result in results:\n",
    "            actual_gmsl_list.append(result[\"act_gmsl\"])\n",
    "            predicted_gmsl_list.append(result[\"pred_gmsl\"])\n",
    "        \n",
    "        # Sum up the MSE and MAE values from the samples and get averages. Perform R^2 calculation.\n",
    "        mse_sum = sum(result[\"mse\"] for result in results)\n",
    "        mae_sum = sum(result[\"mae\"] for result in results)\n",
    "        rmse_sum = sum(result[\"rmse\"] for result in results)\n",
    "        r2 = r2_score(actual_gmsl_list, predicted_gmsl_list)\n",
    "        \n",
    "        n_samples = len(results)\n",
    "\n",
    "        mse_avg = mse_sum / n_samples\n",
    "        mae_avg = mae_sum / n_samples\n",
    "        rmse_avg = rmse_sum / n_samples\n",
    "        \n",
    "        # Returns list of dictionary objects to run function of oaieval.py.\n",
    "        return {\"mse\": mse_avg, \"mae\": mae_avg, \"rmse\": rmse_avg, \"r2\": r2}\n",
    "\n",
    "# This is a function to create an instance of the CompletionFn class in api.py. Called from eval_sample.\n",
    "    def query_model(self, prompt):\n",
    "        response = self.completion_fn(\n",
    "            prompt=prompt\n",
    "        )\n",
    "        # Get and return the resulting sample from the AI.\n",
    "        return response.get_completions()[0]\n",
    "\n",
    "# This function evaluates a single sampled. It is called from eval_all_samples in eval.py. It returns a dictionary\n",
    "# object of recorded metrics which are passed back to eval_all_samples which maintains a list of these dictionary\n",
    "# objects. The return of this function will ultimately be passed to this file's run function.\n",
    "    def eval_sample(self, test_sample, rng: random.Random):\n",
    "        # Stuffing and prompt creation.\n",
    "        stuffing = rng.sample(self.train_samples, self.train_samples_per_prompt)\n",
    "        prompt = [\n",
    "            {\"role\": \"system\", \"content\": \"You will be given Global Mean Sea Level (GMSL) variation WITHOUT\"\n",
    "             \" Global Isostatic Adjustment in mm with respect to TOPEX/Jason collinear mean reference.\"\n",
    "             \" You will also be given the year and fraction of year in decimal form of when the measurement happened.\"\n",
    "             \" Predict the global mean sea level variation WITH global isostatic adjustment (GMSL with GIA)\"\n",
    "            \", in mm, with respect to TOPEX/Jason collinear mean reference.\"\n",
    "             \" Your response should ONLY include the predicted GMSL with GIA in mm.\"},\n",
    "            {\"role\": \"user\", \"content\": \"Date of Measurements: 1993.011526 GMSL without GIA: -38.61\"},\n",
    "            {\"role\": \"assistant\", \"content\": \"-38.64\"},\n",
    "            {\"role\": \"user\", \"content\": \"Date of Measurements: 2010.794397 GMSL without GIA: 14.24\"},\n",
    "            {\"role\": \"assistant\", \"content\": \"18.6\"},\n",
    "            {\"role\": \"user\", \"content\": \"Date of Measurements: 2002.025209 GMSL without GIA: -15.75\"},\n",
    "            {\"role\": \"assistant\", \"content\": \"-13.05\"}\n",
    "        ]\n",
    "        for i, sample in enumerate(stuffing + [test_sample]):\n",
    "            if i < len(stuffing):\n",
    "                prompt += [\n",
    "                    {\"role\": \"system\", \"content\": sample[\"input\"]},\n",
    "                    {\"role\": \"system\", \"content\": sample[\"ideal\"]},\n",
    "                ]\n",
    "            else:\n",
    "                prompt += [{\"role\": \"user\", \"content\": sample[\"input\"]}]\n",
    "        # Call my query_model function and get the result. \n",
    "        model_prediction = self.query_model(prompt)\n",
    "        # Assign this sample's ideal value.\n",
    "        actual_gmsl = float(test_sample[\"ideal\"])\n",
    "        # GPT 3.5 really likes to add all sorts of numbers to the response. We need to parse the correct one.\n",
    "        # This regex gets all the numbers in the sample response.\n",
    "        matches = re.findall(r\"[-]?\\d*\\.\\d+|[-]?\\d+\", model_prediction)\n",
    "        # If there's at least one number, do the following:\n",
    "        if len(matches) >= 1:\n",
    "            # Convert matches to float\n",
    "            matches = [float(match) for match in matches]\n",
    "    \n",
    "            # Remove the actual_gmsl from the list if there are multiple numbers under 1000\n",
    "            if sum(1 for match in matches if match < 1000) > 1:\n",
    "                matches = [match for match in matches if match != actual_gmsl]\n",
    "    \n",
    "            if len(matches) >= 1:\n",
    "                # Assign the smallest number in the list to predicted_gmsl\n",
    "                predicted_gmsl = min(matches)\n",
    "            else:\n",
    "                predicted_gmsl = 0\n",
    "        else:\n",
    "            predicted_gmsl = 0\n",
    "        # Calculate (root) mean squared error ([r]mse) and mean absolute error (mae) below. \n",
    "        mse = (predicted_gmsl - actual_gmsl) ** 2\n",
    "        mae = abs(predicted_gmsl - actual_gmsl)\n",
    "        rmse = sqrt(mse)\n",
    "\n",
    "        # Define metrics and return to eval_all_samples, to ultimately be used in my run function.\n",
    "        metrics = {\n",
    "            \"mse\": mse,\n",
    "            \"mae\": mae,\n",
    "            \"rmse\": rmse,\n",
    "            \"pred_gmsl\": predicted_gmsl,\n",
    "            \"act_gmsl\": actual_gmsl\n",
    "        }\n",
    "    \n",
    "        return metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "434e24a5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
