{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "48912291-80b2-4519-a3fd-483d35d44aa3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bceb9c86-894e-4486-ab8f-d80d0306387a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f1426282-4624-472f-b101-587de2a8755a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from tqdm.auto import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "89e43656-332d-4a3a-88e4-6dd78914fa62",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "log_dir = Path(\"logs/default/generation.direct.gpt-4-1106-preview_corrset_default_1_tree.log\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "38c91891-e71b-4c5f-ab71-8090d09921fd",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from evals.utils import log_utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "542e0e5a-bd79-4382-a161-d8e8e94c669c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "spec = log_utils.extract_spec(log_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "84e2a576-92d4-456e-8e19-b60cfc8e6aa4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def np_nan_if_none(input_num):\n",
    "    if input_num is None:\n",
    "        return np.nan\n",
    "    else:\n",
    "        return input_num\n",
    "    \n",
    "def zero_if_none(input_num):\n",
    "    if input_num is None:\n",
    "        return 0\n",
    "    else:\n",
    "        return input_num"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c57b1c7d-df30-46f0-91c1-e6e92d60a2dd",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def handle_cot_double_sampling(sampling_entries, solver):\n",
    "    if \"cot\" in solver:\n",
    "        sampling_entries = [\n",
    "            entry\n",
    "            for entry in sampling_entries\n",
    "            if (\n",
    "                # for chat models we filter like this\n",
    "                isinstance(entry[\"prompt\"], list)\n",
    "                and entry[\"prompt\"][-1][\"content\"].startswith(\n",
    "                    \"Given the above reasoning\"\n",
    "                )\n",
    "                or (\n",
    "                    # for base models we need to filter like this\n",
    "                    isinstance(entry[\"prompt\"], str)\n",
    "                    and \"Given the above reasoning\" in entry[\"prompt\"]\n",
    "                )\n",
    "            )\n",
    "        ]\n",
    "    return sampling_entries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "abce77bf-9ffd-41eb-929b-746571bae816",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'completion_fns': ['generation/direct/gpt-4-1106-preview'],\n",
       " 'eval_name': 'identifying_variables.corrset.default',\n",
       " 'base_eval': 'identifying_variables',\n",
       " 'split': 'corrset',\n",
       " 'run_config': {'completion_fns': ['generation/direct/gpt-4-1106-preview'],\n",
       "  'eval_spec': {'cls': 'evals.elsuite.identifying_variables.eval:IdentifyingVariables',\n",
       "   'registry_path': '/Users/thesofakillers/repos/dangerous-capability-evaluations/evals/registry',\n",
       "   'args': {'samples_jsonl': 'identifying_variables/500.jsonl',\n",
       "    'renderer': 'corrset',\n",
       "    'group_metrics': True},\n",
       "   'key': 'identifying_variables.corrset.default',\n",
       "   'group': 'identifying_variables'},\n",
       "  'seed': 1,\n",
       "  'max_samples': None,\n",
       "  'command': '/Users/thesofakillers/miniconda3/envs/evals/bin/oaieval generation/direct/gpt-4-1106-preview identifying_variables.corrset.default --extra_eval_param show_tree=True --record_path ./logs/20240112_182258/generation.direct.gpt-4-1106-preview_corrset_default_1_tree.log --seed 1',\n",
       "  'initial_settings': {'visible': True}},\n",
       " 'created_by': '',\n",
       " 'run_id': '240112201333LQ6GP2RW',\n",
       " 'created_at': '2024-01-12 20:13:33.344614'}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "986aa569-0dcd-45a6-8c73-85f75ec477e7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "final_res = log_utils.extract_final_results(log_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2707c121-5a7e-4dd7-ad13-62d7b778ebc1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "ind_res = log_utils.extract_individual_results(log_dir, \"sampling\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "cc3a1839-dbfc-4b0f-b044-b3a633d1c364",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "500"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(ind_res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "8a10da5b-334a-4ee0-aa33-c8481075bfa4",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'completion_tokens': 9, 'prompt_tokens': 869, 'total_tokens': 878}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ind_res[0]['usage']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "9154e7a1-57da-417d-b46a-df33760ee0ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_names = [\n",
    "    \"identifying_variables.corrset.default\",\n",
    "    \"identifying_variables.language-tabular.default\",\n",
    "]\n",
    "solver_names = [\n",
    "    \"generation/hhh/gpt-4-base\",\n",
    "    \"generation/direct/gpt-3.5-turbo\",\n",
    "    \"generation/direct/gpt-4-1106-preview\",\n",
    "    \"generation/cot_hhh/gpt-4-base\",\n",
    "    \"generation/cot/gpt-3.5-turbo\",\n",
    "    \"generation/cot/gpt-4-1106-preview\",\n",
    "]\n",
    "solver_to_eval = {\n",
    "    solver: eval_names[0] if \"cot\" not in solver else eval_names[1]\n",
    "    for solver in solver_names\n",
    "}\n",
    "solver_to_tree = {\n",
    "    solver: False if \"cot\" not in solver else True for solver in solver_names\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "388e0b27-901e-4fb8-9af2-008422b29bc2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "caa07303-4a5e-4132-9186-255afe7a8cc2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "tokens_per_sample_df = pd.DataFrame(\n",
    "    index=solver_to_eval.keys(),\n",
    "    columns=[\"input tokens/sample\", \"output tokens/sample\", \"total tokens/sample\"],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "f6a56622-310e-43d5-941b-3e51f82907f8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "results_dir = Path(\"logs/default/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "ae659b3d-ecbf-4d65-95f4-ac41bc8ece55",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "24c862b329d34c2fbbe6fd3e1d2867d1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/222 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "solver_to_tokens = {\n",
    "    solver: {\"input\": [], \"output\": [], \"total\": []} for solver in solver_names\n",
    "}\n",
    "total_input = 0\n",
    "total_output = 0\n",
    "for log in tqdm(results_dir.glob(\"*.log\"), total=222):\n",
    "    spec = log_utils.extract_spec(log)\n",
    "    solver = spec[\"completion_fns\"][0]\n",
    "    eval_name = spec[\"eval_name\"]\n",
    "    seed = spec[\"run_config\"][\"seed\"]\n",
    "    tree = \"show_tree=True\" in spec[\"run_config\"][\"command\"]\n",
    "    samplings = log_utils.extract_individual_results(log, \"sampling\")\n",
    "    samplings = handle_cot_double_sampling(samplings, solver)\n",
    "    for sampling in samplings:\n",
    "        usage = sampling[\"usage\"]\n",
    "        if (\n",
    "            solver in solver_to_eval\n",
    "            and eval_name == solver_to_eval[solver]\n",
    "            and seed == 1\n",
    "            and tree != solver_to_tree[solver]\n",
    "        ):\n",
    "            solver_to_tokens[solver][\"input\"].append(\n",
    "                np_nan_if_none(usage[\"prompt_tokens\"])\n",
    "            )\n",
    "            solver_to_tokens[solver][\"output\"].append(\n",
    "                np_nan_if_none(usage[\"completion_tokens\"])\n",
    "            )\n",
    "            solver_to_tokens[solver][\"total\"].append(\n",
    "                np_nan_if_none(usage[\"total_tokens\"])\n",
    "            )\n",
    "        total_input += zero_if_none(usage[\"prompt_tokens\"])\n",
    "        total_output += zero_if_none(usage[\"completion_tokens\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "7b295468-3b56-4381-acb3-698a6325a990",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "179460552"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "total_input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "e16a1faf-e6a6-4628-b8c9-b7205704fba6",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "24819644"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "total_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "666c3cca-650f-4b6b-8fa8-e170dfacdcb5",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "500"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(solver_to_tokens['generation/direct/gpt-3.5-turbo']['output'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "4ff2378f-f33f-4c8e-9a53-947178dc15f6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "for solver in solver_to_tokens.keys():\n",
    "    # print(solver_to_tokens[solver])\n",
    "    input_mean = np.nanmean(solver_to_tokens[solver][\"input\"])\n",
    "    output_mean = np.nanmean(solver_to_tokens[solver][\"output\"])\n",
    "    total_mean = np.nanmean(solver_to_tokens[solver][\"total\"])\n",
    "    # print([input_mean, output_mean, total_mean])\n",
    "    tokens_per_sample_df.loc[solver] = [\n",
    "        round(input_mean),\n",
    "        round(output_mean),\n",
    "        round(total_mean),\n",
    "    ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "b2f59022-9c3e-4436-ba5f-3a5d3f995744",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "solver_to_index = {\n",
    "    \"generation/hhh/gpt-4-base\": \"HHH GPT-4-base (corrset, no tree)\",\n",
    "    \"generation/direct/gpt-3.5-turbo\": \"Direct GPT-3.5-turbo (corrset, no tree)\",\n",
    "    \"generation/direct/gpt-4-1106-preview\": \"Direct GPT-4-1106-preview (corrset, no tree)\",\n",
    "    \"generation/cot_hhh/gpt-4-base\": \"CoT HHH GPT-4-base (language-tabular, with tree)\",\n",
    "    \"generation/cot/gpt-3.5-turbo\": \"CoT GPT-3.5-turbo (language-tabular, with tree)\",\n",
    "    \"generation/cot/gpt-4-1106-preview\": \"CoT GPT-4-1106-preview (language-tabular, with tree)\",\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "817c5b4d-046c-4dd2-9eea-25da86e328da",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "tokens_per_sample_df = tokens_per_sample_df.rename(index=solver_to_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "e1c66211-0923-4caf-b2d7-c70b55b4d509",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>input tokens/sample</th>\n",
       "      <th>output tokens/sample</th>\n",
       "      <th>total tokens/sample</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>HHH GPT-4-base (corrset, no tree)</th>\n",
       "      <td>2294</td>\n",
       "      <td>496</td>\n",
       "      <td>2790</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Direct GPT-3.5-turbo (corrset, no tree)</th>\n",
       "      <td>851</td>\n",
       "      <td>176</td>\n",
       "      <td>1026</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Direct GPT-4-1106-preview (corrset, no tree)</th>\n",
       "      <td>851</td>\n",
       "      <td>106</td>\n",
       "      <td>957</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CoT HHH GPT-4-base (language-tabular, with tree)</th>\n",
       "      <td>2850</td>\n",
       "      <td>476</td>\n",
       "      <td>3325</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CoT GPT-3.5-turbo (language-tabular, with tree)</th>\n",
       "      <td>1560</td>\n",
       "      <td>27</td>\n",
       "      <td>1587</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CoT GPT-4-1106-preview (language-tabular, with tree)</th>\n",
       "      <td>1711</td>\n",
       "      <td>27</td>\n",
       "      <td>1738</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   input tokens/sample  \\\n",
       "HHH GPT-4-base (corrset, no tree)                                 2294   \n",
       "Direct GPT-3.5-turbo (corrset, no tree)                            851   \n",
       "Direct GPT-4-1106-preview (corrset, no tree)                       851   \n",
       "CoT HHH GPT-4-base (language-tabular, with tree)                  2850   \n",
       "CoT GPT-3.5-turbo (language-tabular, with tree)                   1560   \n",
       "CoT GPT-4-1106-preview (language-tabular, with ...                1711   \n",
       "\n",
       "                                                   output tokens/sample  \\\n",
       "HHH GPT-4-base (corrset, no tree)                                   496   \n",
       "Direct GPT-3.5-turbo (corrset, no tree)                             176   \n",
       "Direct GPT-4-1106-preview (corrset, no tree)                        106   \n",
       "CoT HHH GPT-4-base (language-tabular, with tree)                    476   \n",
       "CoT GPT-3.5-turbo (language-tabular, with tree)                      27   \n",
       "CoT GPT-4-1106-preview (language-tabular, with ...                   27   \n",
       "\n",
       "                                                   total tokens/sample  \n",
       "HHH GPT-4-base (corrset, no tree)                                 2790  \n",
       "Direct GPT-3.5-turbo (corrset, no tree)                           1026  \n",
       "Direct GPT-4-1106-preview (corrset, no tree)                       957  \n",
       "CoT HHH GPT-4-base (language-tabular, with tree)                  3325  \n",
       "CoT GPT-3.5-turbo (language-tabular, with tree)                   1587  \n",
       "CoT GPT-4-1106-preview (language-tabular, with ...                1738  "
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokens_per_sample_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d054923-c050-46db-9d47-8f5001aef29f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "evals",
   "language": "python",
   "name": "evals"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
