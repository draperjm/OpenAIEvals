{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "48912291-80b2-4519-a3fd-483d35d44aa3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "f1426282-4624-472f-b101-587de2a8755a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from tqdm.auto import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "89e43656-332d-4a3a-88e4-6dd78914fa62",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "log_dir = Path(\"logs/default/generation.direct.gpt-4-1106-preview_corrset_default_1_tree.log\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "38c91891-e71b-4c5f-ab71-8090d09921fd",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from evals.utils import log_utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "542e0e5a-bd79-4382-a161-d8e8e94c669c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "spec = log_utils.extract_spec(log_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "c57b1c7d-df30-46f0-91c1-e6e92d60a2dd",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def handle_cot_double_sampling(sampling_entries, solver):\n",
    "    if \"cot\" in solver:\n",
    "        sampling_entries = [\n",
    "            entry\n",
    "            for entry in sampling_entries\n",
    "            if (\n",
    "                # for chat models we filter like this\n",
    "                isinstance(entry[\"prompt\"], list)\n",
    "                and entry[\"prompt\"][-1][\"content\"].startswith(\n",
    "                    \"Given the above reasoning\"\n",
    "                )\n",
    "                or (\n",
    "                    # for base models we need to filter like this\n",
    "                    isinstance(entry[\"prompt\"], str)\n",
    "                    and \"Given the above reasoning\" in entry[\"prompt\"]\n",
    "                )\n",
    "            )\n",
    "        ]\n",
    "    return sampling_entries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "abce77bf-9ffd-41eb-929b-746571bae816",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'completion_fns': ['generation/direct/gpt-4-1106-preview'],\n",
       " 'eval_name': 'identifying_variables.corrset.default',\n",
       " 'base_eval': 'identifying_variables',\n",
       " 'split': 'corrset',\n",
       " 'run_config': {'completion_fns': ['generation/direct/gpt-4-1106-preview'],\n",
       "  'eval_spec': {'cls': 'evals.elsuite.identifying_variables.eval:IdentifyingVariables',\n",
       "   'registry_path': '/Users/thesofakillers/repos/dangerous-capability-evaluations/evals/registry',\n",
       "   'args': {'samples_jsonl': 'identifying_variables/500.jsonl',\n",
       "    'renderer': 'corrset',\n",
       "    'group_metrics': True},\n",
       "   'key': 'identifying_variables.corrset.default',\n",
       "   'group': 'identifying_variables'},\n",
       "  'seed': 1,\n",
       "  'max_samples': None,\n",
       "  'command': '/Users/thesofakillers/miniconda3/envs/evals/bin/oaieval generation/direct/gpt-4-1106-preview identifying_variables.corrset.default --extra_eval_param show_tree=True --record_path ./logs/20240112_182258/generation.direct.gpt-4-1106-preview_corrset_default_1_tree.log --seed 1',\n",
       "  'initial_settings': {'visible': True}},\n",
       " 'created_by': '',\n",
       " 'run_id': '240112201333LQ6GP2RW',\n",
       " 'created_at': '2024-01-12 20:13:33.344614'}"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "986aa569-0dcd-45a6-8c73-85f75ec477e7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "final_res = log_utils.extract_final_results(log_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "2707c121-5a7e-4dd7-ad13-62d7b778ebc1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "ind_res = log_utils.extract_individual_results(log_dir, \"sampling\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "cc3a1839-dbfc-4b0f-b044-b3a633d1c364",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "500"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(ind_res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "8a10da5b-334a-4ee0-aa33-c8481075bfa4",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'completion_tokens': 248, 'prompt_tokens': 541, 'total_tokens': 789}"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ind_res[0]['usage']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "9154e7a1-57da-417d-b46a-df33760ee0ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_names = [\n",
    "    \"identifying_variables.corrset.default\",\n",
    "    \"identifying_variables.language-tabular.default\",\n",
    "]\n",
    "solver_names = [\n",
    "    \"generation/hhh/gpt-4-base\",\n",
    "    \"generation/direct/gpt-3.5-turbo\",\n",
    "    \"generation/direct/gpt-4-1106-preview\",\n",
    "    \"generation/cot_hhh/gpt-4-base\",\n",
    "    \"generation/cot/gpt-3.5-turbo\",\n",
    "    \"generation/cot/gpt-4-1106-preview\",\n",
    "]\n",
    "solver_to_eval = {\n",
    "    solver: eval_names[0] if \"cot\" not in solver else eval_names[1]\n",
    "    for solver in solver_names\n",
    "}\n",
    "solver_to_tree = {\n",
    "    solver: False if \"cot\" not in solver else True for solver in solver_names\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "388e0b27-901e-4fb8-9af2-008422b29bc2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "caa07303-4a5e-4132-9186-255afe7a8cc2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "tokens_per_sample_df = pd.DataFrame(\n",
    "    index=solver_to_eval.keys(),\n",
    "    columns=[\"input tokens/sample\", \"output tokens/sample\", \"total tokens/sample\"],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "f6a56622-310e-43d5-941b-3e51f82907f8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "results_dir = Path(\"logs/default/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "84e2a576-92d4-456e-8e19-b60cfc8e6aa4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def np_nan_if_none(input_num):\n",
    "    if input_num is None:\n",
    "        return np.nan\n",
    "    else:\n",
    "        return input_num"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "ae659b3d-ecbf-4d65-95f4-ac41bc8ece55",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "15d78f6a5d6b4feeb02f5c295385b936",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/222 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "generation/cot/gpt-4-1106-preview\n",
      "generation/hhh/gpt-4-base\n",
      "generation/direct/gpt-3.5-turbo\n",
      "generation/cot_hhh/gpt-4-base\n",
      "generation/direct/gpt-4-1106-preview\n",
      "generation/cot/gpt-3.5-turbo\n"
     ]
    }
   ],
   "source": [
    "solver_to_tokens = {\n",
    "    solver: {\"input\": [], \"output\": [], \"total\": []} for solver in solver_names\n",
    "}\n",
    "for log in tqdm(results_dir.glob(\"*.log\"), total=222):\n",
    "    spec = log_utils.extract_spec(log)\n",
    "    solver = spec[\"completion_fns\"][0]\n",
    "    eval_name = spec[\"eval_name\"]\n",
    "    seed = spec[\"run_config\"][\"seed\"]\n",
    "    tree = \"show_tree=True\" in spec[\"run_config\"][\"command\"]\n",
    "    if not (\n",
    "        solver in solver_to_eval\n",
    "        and eval_name == solver_to_eval[solver]\n",
    "        and seed == 1\n",
    "        and tree != solver_to_tree[solver]\n",
    "    ):\n",
    "        # not a solver for interest\n",
    "        continue\n",
    "    print(solver)\n",
    "    samplings = log_utils.extract_individual_results(log, \"sampling\")\n",
    "    samplings = handle_cot_double_sampling(samplings, solver)\n",
    "    for sampling in samplings:\n",
    "        usage = sampling[\"usage\"]\n",
    "        solver_to_tokens[solver][\"input\"].append(np_nan_if_none(usage[\"prompt_tokens\"]))\n",
    "        solver_to_tokens[solver][\"output\"].append(\n",
    "            np_nan_if_none(usage[\"completion_tokens\"])\n",
    "        )\n",
    "        solver_to_tokens[solver][\"total\"].append(np_nan_if_none(usage[\"total_tokens\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "666c3cca-650f-4b6b-8fa8-e170dfacdcb5",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "500"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(solver_to_tokens['generation/direct/gpt-3.5-turbo']['output'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "bceb9c86-894e-4486-ab8f-d80d0306387a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "4ff2378f-f33f-4c8e-9a53-947178dc15f6",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[850.766, 175.506, 1026.272]\n",
      "[850.766, 106.1, 956.866]\n",
      "[2293.766, 496.382, 2790.148]\n",
      "[1560.354, 27.096, 1587.45]\n",
      "[1710.938, 26.722, 1737.66]\n",
      "[2849.714, 475.9899799599198, 3324.752]\n"
     ]
    }
   ],
   "source": [
    "for solver in solver_to_tokens.keys():\n",
    "    # print(solver_to_tokens[solver])\n",
    "    input_mean = np.nanmean(solver_to_tokens[solver][\"input\"])\n",
    "    output_mean = np.nanmean(solver_to_tokens[solver][\"output\"])\n",
    "    total_mean = np.nanmean(solver_to_tokens[solver][\"total\"])\n",
    "    # print([input_mean, output_mean, total_mean])\n",
    "    tokens_per_sample_df.loc[solver] = [input_mean, output_mean, total_mean]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "b2f59022-9c3e-4436-ba5f-3a5d3f995744",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>input tokens/sample</th>\n",
       "      <th>output tokens/sample</th>\n",
       "      <th>total tokens/sample</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>generation/direct/gpt-3.5-turbo</th>\n",
       "      <td>850.766</td>\n",
       "      <td>175.506</td>\n",
       "      <td>1026.272</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>generation/direct/gpt-4-1106-preview</th>\n",
       "      <td>850.766</td>\n",
       "      <td>106.1</td>\n",
       "      <td>956.866</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>generation/hhh/gpt-4-base</th>\n",
       "      <td>2293.766</td>\n",
       "      <td>496.382</td>\n",
       "      <td>2790.148</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>generation/cot/gpt-3.5-turbo</th>\n",
       "      <td>1560.354</td>\n",
       "      <td>27.096</td>\n",
       "      <td>1587.45</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>generation/cot/gpt-4-1106-preview</th>\n",
       "      <td>1710.938</td>\n",
       "      <td>26.722</td>\n",
       "      <td>1737.66</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>generation/cot_hhh/gpt-4-base</th>\n",
       "      <td>2849.714</td>\n",
       "      <td>475.98998</td>\n",
       "      <td>3324.752</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                     input tokens/sample output tokens/sample  \\\n",
       "generation/direct/gpt-3.5-turbo                  850.766              175.506   \n",
       "generation/direct/gpt-4-1106-preview             850.766                106.1   \n",
       "generation/hhh/gpt-4-base                       2293.766              496.382   \n",
       "generation/cot/gpt-3.5-turbo                    1560.354               27.096   \n",
       "generation/cot/gpt-4-1106-preview               1710.938               26.722   \n",
       "generation/cot_hhh/gpt-4-base                   2849.714            475.98998   \n",
       "\n",
       "                                     total tokens/sample  \n",
       "generation/direct/gpt-3.5-turbo                 1026.272  \n",
       "generation/direct/gpt-4-1106-preview             956.866  \n",
       "generation/hhh/gpt-4-base                       2790.148  \n",
       "generation/cot/gpt-3.5-turbo                     1587.45  \n",
       "generation/cot/gpt-4-1106-preview                1737.66  \n",
       "generation/cot_hhh/gpt-4-base                   3324.752  "
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokens_per_sample_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "817c5b4d-046c-4dd2-9eea-25da86e328da",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "evals",
   "language": "python",
   "name": "evals"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
