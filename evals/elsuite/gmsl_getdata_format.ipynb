{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f13276f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download data set at NASA Earthdata Search. Collection name: \n",
    "# Global Mean Sea Level Trend from Integrated Multi-Mission Ocean Altimeters TOPEX/Poseidon, Jason-1, OSTM/Jason-2, and Jason-3 Version 5.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b42b6d40",
   "metadata": {},
   "outputs": [],
   "source": [
    "# GSFC. 2021. Global Mean Sea Level Trend from Integrated Multi-Mission Ocean Altimeters TOPEX/Poseidon\n",
    "# Jason-1, OSTM/Jason-2, and Jason-3 Version 5.1. Ver. 5.1 PO.DAAC, CA, USA.\n",
    "# Dataset accessed [2023-04-20] at https://doi.org/10.5067/GMSLM-TJ151."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f1ce2fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download the dataset and save it in this directory as data.txt.\n",
    "# Read the header information of the data, and then remove it and run this script.\n",
    "# This script will turn the data into CSV and generate your sample, test, and train data \n",
    "# using K-fold cross validation. These files will be saved as properly-formatted JSON for use with\n",
    "# OpenAI evals framework."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "257c1f94",
   "metadata": {},
   "outputs": [],
   "source": [
    "import openai\n",
    "import os\n",
    "import random\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import KFold\n",
    "from typing import List\n",
    "import numpy as np\n",
    "from math import sqrt\n",
    "from sklearn.metrics import r2_score\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3f0aa4fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "class GMSLPredictor:\n",
    "\n",
    "    def __init__(self, api_key, train_samples, train_samples_per_prompt=15):\n",
    "        self.api_key = api_key\n",
    "        self.train_samples = train_samples\n",
    "        self.train_samples_per_prompt = train_samples_per_prompt\n",
    "        openai.api_key = self.api_key\n",
    "\n",
    "    def query_model(self, prompt):\n",
    "        prompt_str = \"\"\n",
    "        for item in prompt:\n",
    "            if item[\"role\"] == \"system\":\n",
    "                prompt_str += item[\"content\"] + \"\\n\"\n",
    "            else:\n",
    "                prompt_str += \"User: \" + item[\"content\"] + \"\\n\"\n",
    "\n",
    "        response = openai.ChatCompletion.create(\n",
    "            model=\"gpt-3.5-turbo\",\n",
    "            messages=[{\"role\": \"system\", \"content\": prompt_str}]\n",
    "        )\n",
    "        with open(f\"Logs/logfile.txt\", \"+a\") as file:\n",
    "            file.write(f\"Prompt_str: {prompt_str} Response = {response}\")\n",
    "        return response.choices[0].message.content\n",
    "\n",
    "    def eval_sample(self, test_sample, rng: random.Random):\n",
    "        stuffing = rng.sample(self.train_samples, self.train_samples_per_prompt)\n",
    "\n",
    "        prompt = [\n",
    "            {\"role\": \"system\", \"content\": \"You will be given Global Mean Sea Level (GMSL) variation WITHOUT\"\n",
    "             \" Global Isostatic Adjustment in mm with respect to TOPEX/Jason collinear mean reference.\"\n",
    "             \" You will also be given the year and fraction of year in decimal form of when the measurement happened.\"\n",
    "             \" Predict the global mean sea level variation WITH global isostatic adjustment (GMSL with GIA)\"\n",
    "            \", in mm, with respect to TOPEX/Jason collinear mean reference.\"\n",
    "             \" Your response should only include the predicted GMSL with GIA in mm.\"},\n",
    "            {\"role\": \"user\", \"content\": \"GMSL without GIA: -42.71\"},\n",
    "            {\"role\": \"assistant\", \"content\": \"-42.69\"},\n",
    "            {\"role\": \"user\", \"content\": \"GMSL without GIA: -31.15\"},\n",
    "            {\"role\": \"assistant\", \"content\": \"-30.91\"}\n",
    "        ]\n",
    "\n",
    "        for i, sample in enumerate(stuffing + [test_sample]):\n",
    "            if i < len(stuffing):\n",
    "                prompt += [\n",
    "                    {\"role\": \"system\", \"content\": sample[\"input\"]},\n",
    "                    {\"role\": \"system\", \"content\": sample[\"ideal\"]},\n",
    "                ]\n",
    "            else:\n",
    "                prompt += [{\"role\": \"user\", \"content\": sample[\"input\"]}]\n",
    "\n",
    "        model_prediction = self.query_model(prompt)\n",
    "        return float(model_prediction), float(test_sample[\"ideal\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "866e4a66",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"Data/data.csv\")\n",
    "data_sample = pd.read_csv(\"Data/data.csv\", nrows=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c8b28e8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "samples = []\n",
    "\n",
    "for index, row in data_sample.iterrows():\n",
    "    input_values = f\"GMSL without GIA: {row['GMSL_variation_no_GIA']}.\"\n",
    "    prompt = [\n",
    "        {\"role\": \"system\", \"content\": \"You will be given Global Mean Sea Level (GMSL) variation WITHOUT\"\n",
    "                 \" Global Isostatic Adjustment in mm with respect to TOPEX/Jason collinear mean reference.\"\n",
    "                 \" You will also be given the year and fraction of year in decimal form of when the measurement happened.\"\n",
    "                 \" Predict the global mean sea level variation WITH global isostatic adjustment (GMSL with GIA)\"\n",
    "                \", in mm, with respect to TOPEX/Jason collinear mean reference.\"\n",
    "                 \" Your response should only include the predicted GMSL with GIA in mm.\"},\n",
    "        {\"role\": \"user\", \"content\": input_values}\n",
    "    ]\n",
    "    ideal = str(row[\"GMSL_variation_with_GIA\"])\n",
    "    samples.append({\"input\": prompt, \"ideal\": ideal})\n",
    "        \n",
    "with open(\"samples.jsonl\", \"w\") as f:\n",
    "    for sample in samples:\n",
    "        f.write(json.dumps(sample) + \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09b51b92",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_jsonl(prompt, ideal):\n",
    "    return {\"input\": prompt, \"ideal\": ideal}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5066e2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "jsonl_data = []\n",
    "i = 0\n",
    "for index, row in data.iterrows():\n",
    "    input_values = f\"Date of measurements: {row['year_fraction']} GMSL without GIA: {row['GMSL_variation_no_GIA']}.\"\n",
    "    prompt = input_values\n",
    "    ideal = str(row[\"GMSL_variation_with_GIA\"])\n",
    "    jsonl = create_jsonl(prompt, ideal)\n",
    "    jsonl_data.append(jsonl)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b17dddd",
   "metadata": {},
   "outputs": [],
   "source": [
    "kf = KFold(n_splits=5)\n",
    "\n",
    "train_samples_all = []\n",
    "test_samples_all = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d2571df",
   "metadata": {},
   "outputs": [],
   "source": [
    "for train_index, test_index in kf.split(jsonl_data):\n",
    "    train_samples = [jsonl_data[i] for i in train_index]\n",
    "    test_samples = [jsonl_data[i] for i in test_index]\n",
    "    train_samples_all.extend(train_samples)\n",
    "    test_samples_all.extend(test_samples)\n",
    "    \n",
    "# Write train samples to the train.jsonl file\n",
    "with open(f\"train.jsonl\", \"w\") as file:\n",
    "    for sample in train_samples_all:\n",
    "        file.write(json.dumps(sample) + \"\\n\")\n",
    "\n",
    "# Write test samples to the test.jsonl file\n",
    "with open(f\"test.jsonl\", \"w\") as file:\n",
    "    for sample in test_samples_all:\n",
    "        file.write(json.dumps(sample) + \"\\n\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
