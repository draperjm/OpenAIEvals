# A MECE list of LLM evaluation tasks

A "MECE" (Mutually Exclusive and Collectively Exhaustive) list of evaluation tasks for large language models (LLMs)
would attempt to cover all possible aspects of natural language understanding and generation without overlapping. While
it is challenging to create a perfect MECE list, here is an attempt to categorize evaluation tasks for LLMs:

## 1. Language Understanding Tasks

- Sentiment Analysis
- Text Classification
- Named Entity Recognition
- Coreference Resolution
- Semantic Role Labeling
- Relation Extraction
- Part-of-Speech Tagging
- Dependency Parsing
- Word Sense Disambiguation
- Reading Comprehension

## 2. Language Generation Tasks

- Text Summarization
- Machine Translation
- Paraphrasing
- Text Simplification
- Image Captioning
- Storytelling
- Dialogue Generation
- Writing Assistance

## 3. Multimodal Tasks

- Visual Question Answering
- Visual Dialog
- Visual Commonsense Reasoning

## 4. Commonsense Reasoning

- Question Answering
- Analogical Reasoning
- Causal Reasoning
- Temporal Reasoning
- Spatial Reasoning

## 5. Knowledge-based Tasks

- Fact Checking
- Knowledge Graph Completion
- Entity Linking
- Knowledge Retrieval

## 6. Adversarial and Robustness Evaluation

- Adversarial Example Detection
- Out-of-Distribution Detection
- Bias and Fairness Evaluation

While this list attempts to cover a wide range of tasks, it may not be fully exhaustive or perfectly mutually exclusive,
as some tasks can overlap or be related. Nonetheless, this list should provide a solid foundation for evaluating the
performance of LLMs.
