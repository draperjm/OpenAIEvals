Pull request 534 describes an evaluation method called "Moral-exceptQA" that tests a GPT model's ability to align with human intuition on when it is acceptable to break an established moral norm. The evaluation is based on binary choice questions with answers about whether it is moral to break common rules under specific circumstances. The evaluation is considered useful for AI safety as it deals with the capability of understanding ethics in relation to heterogeneous contexts. The evaluation is built upon novel research on AI alignment and will contribute to the reliability and safety of GPT models. The evaluation data is provided in JSON format.