Pull request 257 describes an evaluation method called CREPE, which is a benchmark for a model's causal reasoning. The dataset consists of procedures and imaginary events, and the labels are the change in the likelihood of the imaginary events from happening throughout a procedure. The language model takes the procedure up to the current step and the imaginary event as input and predicts the likelihood that the event happens at the current step compared to the previous step. The label space is {"more likely", "less likely", "equally likely"}. This evaluation is useful for testing a GPT-4 model's causal reasoning capability, commonsense knowledge, and ability to conduct causal reasoning with commonsense knowledge. The evaluation includes JSON data with input and ideal outputs.