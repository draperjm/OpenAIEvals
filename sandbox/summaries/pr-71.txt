Pull request 71 proposes a new evaluation method called "Pattern identification". The task requires the model to identify a pattern in a set of inputs and outputs and answer with either "foo" or "bar". The evaluation is designed to test the model's ability to reason and perform true pattern identification in-context. The evaluation consists of eight examples, and the pattern is the same for all of them. The evaluation results show that GPT-4 outperforms GPT-3.5-Turbo and a random baseline. The evaluation is considered useful because it tests the model's ability to perform true symbolic manipulations, which is a significant failure case for language models.