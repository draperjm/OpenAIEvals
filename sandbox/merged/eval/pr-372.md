## Title: Add Belarusian lexicon eval

## Body:

### Eval name

belarusian-lexicon

### Eval description

Test the model's ability to distinguish between existing and hallucinated Belarusian words.

### What makes this a useful eval?

While the multilingual capability of recent GPT models is impressive, there is still room for improvement. Many human
languages are lagging far behind English in terms of the model's ability to answer questions and produce coherent texts
in these languages, and the model's "knowledge" of their lexicon and grammar is, to some extent, hallucinated. One
example is Belarusian, an East Slavic language spoken by several million people. In my experience with ChatGPT, when the
model is prompted in Belarusian, its responses are sometimes ungrammatical or semantically incoherent, and very often
they contain made-up words – a possible sign of over generalization based on Russian and Ukrainian data, which are much
more [abundant](https://commoncrawl.github.io/cc-crawl-statistics/plots/languages) on the web than Belarusian.

This eval contains 150 pairs of single-word prompts: one item in each pair is a non-word hallucinated by ChatGPT (either
totally meaningless in Belarusian or violating the language's orthographic and phonetic rules), and another item is an
actual Belarusian word with similar spelling. The model's task is to distinguish between words and non-words. ChatGPT
tends to label most items as existing words, therefore its accuracy appears to be around 50%, and the negative-class F
measure is very low. Any competent speaker of Belarusian would perform much better, and a language-specific tool, such
as [this spell checker](https://corpus.by/SpellChecker)
or [this grammatical database](https://bnkorpus.info/grammar.en.html) of Belarusian (also available
for [download](https://github.com/Belarus/GrammarDB/releases)), would flawlessly identify non-words.

### Unique eval value

This eval an attempt to point out specific deficiencies in the model's ability to handle a lower-resource language (
Belarusian). As such, it might not only benchmark future refinements of Belarusian language capability in the GPT
models, but also serve as an instructive example for other language communities.

### Eval JSON data

<details>

  <summary>View evals in JSON</summary>

### Eval

  ```jsonl

  {"input": [{"role": "system", "content": "You will be prompted with a single word. Does this word exist in Belarusian language? Answer Y or N."}, {"role": "user", "content": "абвязкою"}], "ideal": "N"}

  {"input": [{"role": "system", "content": "You will be prompted with a single word. Does this word exist in Belarusian language? Answer Y or N."}, {"role": "user", "content": "абвязкаю"}], "ideal": "Y"}

  {"input": [{"role": "system", "content": "You will be prompted with a single word. Does this word exist in Belarusian language? Answer Y or N."}, {"role": "user", "content": "абласці"}], "ideal": "N"}

  {"input": [{"role": "system", "content": "You will be prompted with a single word. Does this word exist in Belarusian language? Answer Y or N."}, {"role": "user", "content": "вобласці"}], "ideal": "Y"}

  {"input": [{"role": "system", "content": "You will be prompted with a single word. Does this word exist in Belarusian language? Answer Y or N."}, {"role": "user", "content": "абмяну"}], "ideal": "N"}

  ```

</details>


