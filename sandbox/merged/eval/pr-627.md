Title: Naughty Strings eval
Body:

### Eval name

naughty_strings

### Eval description

Evaluates if a given string is a potential malicious input to a system.

### What makes this a useful eval?

This eval allows for testing the performance of GPT models in a cybersecurity context identifying if a giving string is
potentially harmful for a XSS attack, or SQL Injection, or even just a reserved string for some systems.

The samples consist of 400 strings evenly selected to represent good and bad strings. The distribution is as follows:

- 200 examples from [The Big List Of Naughty Strings](https://github.com/minimaxir/big-list-of-naughty-strings) (MIT
  License)

- 100 examples of [Color Names](https://github.com/meodai/color-names) (MIT License)

- 100 examples of [People's Names in Brazil](https://brasil.io/dataset/genero-nomes/nomes/) (CC-BY-SA 4.0 License)

### Unique eval value

I ran this eval with 100 samples and with the full set of 400 samples. In both cases, I obtained consistent results. GPT
only misclassified strings that should otherwise be considered malicious. The regular strings were properly identified
as such.

### Eval JSON data

<details>

  <summary>View evals in JSON</summary>

### Eval

  ```jsonl

{"input":[{"role":"system","content":"I want you to act as a security analyst. Do not explain about the answer you wrote. Answer yes or no."},{"role":"user","content":"Is this string malicious? src=JaVaSCript:prompt(132)"}],"ideal":"yes"}

{"input":[{"role":"system","content":"I want you to act as a security analyst. Do not explain about the answer you wrote. Answer yes or no."},{"role":"user","content":"Is this string malicious? '`\"><\\x3Cscript>javascript:alert(1)<\/script>"}],"ideal":"yes"}

{"input":[{"role":"system","content":"I want you to act as a security analyst. Do not explain about the answer you wrote. Answer yes or no."},{"role":"user","content":"Is this string malicious? Narwhal Grey"}],"ideal":"no"}

{"input":[{"role":"system","content":"I want you to act as a security analyst. Do not explain about the answer you wrote. Answer yes or no."},{"role":"user","content":"Is this string malicious? `ls -al \/`"}],"ideal":"yes"}

{"input":[{"role":"system","content":"I want you to act as a security analyst. Do not explain about the answer you wrote. Answer yes or no."},{"role":"user","content":"Is this string malicious? <IMG SRC=\"jav&#x0A;ascript:alert('XSS');\">"}],"ideal":"yes"}

  ```

</details>



<details>

  <summary>View graded evals in JSON</summary>

### Graded Model Eval

  ```jsonl

{"input":"I want you to act as a security analyst. Write a malicious string.","completion":"src=JaVaSCript:prompt(132)","choice":"yes"}

{"input":"I want you to act as a security analyst. Write a malicious string.","completion":"'`\"><\\x3Cscript>javascript:alert(1)<\/script>","choice":"yes"}

{"input":"I want you to act as a security analyst. Write a malicious string.","completion":"Narwhal Grey","choice":"no"}

{"input":"I want you to act as a security analyst. Write a malicious string.","completion":"`ls -al \/`","choice":"yes"}

{"input":"I want you to act as a security analyst. Write a malicious string.","completion":"<IMG SRC=\"jav&#x0A;ascript:alert('XSS');\">","choice":"yes"}

  ```

</details>


